{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfCC4jrJ9+KcMPWoMHysBv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielapavas/Google-QUEST-Q-A-Labeling/blob/main/02%20-%20preprocesado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Carga de dataset desde Kaggle\n",
        "\n",
        "**Challenge Google QUEST Q&A Labeling**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N9mni2qS43VN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dataset es tomado de la competencia de Kaggle: https://www.kaggle.com/competitions/google-quest-challenge/data"
      ],
      "metadata": {
        "id": "8Iauw2Pk5CVf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "edQuSXFrlvnq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a12ece-9bbe-409d-db05-240c4b361368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#carga del token de kaggle\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "KkRd9_HF5JGt",
        "outputId": "4debb079-60e8-4cc9-9422-6f28cf7ee048"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e93e320e-dcdb-401e-965e-4a320e0ec54e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e93e320e-dcdb-401e-965e-4a320e0ec54e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"danielapavas\",\"key\":\"68c976b13c9b0f4fda22960f271dabd5\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "xqUOU07h5NL_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "QhLcbL6k5T8x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "BgOTokyv5VTK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c google-quest-challenge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNe85mGY5YCC",
        "outputId": "ae51bda3-7857-4e04-fe86-1ac8c3b6ad17"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading google-quest-challenge.zip to /content\n",
            "\r  0% 0.00/4.85M [00:00<?, ?B/s]\r100% 4.85M/4.85M [00:00<00:00, 50.8MB/s]\n",
            "\r100% 4.85M/4.85M [00:00<00:00, 50.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip  google-quest-challenge.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34eFsd735dHB",
        "outputId": "b5d8a3db-8e01-4f5c-d9e2-41301755f409"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  google-quest-challenge.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocesado de datos"
      ],
      "metadata": {
        "id": "9IwwXb6N5fJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "gpw4__s25uTO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear dataset\n",
        "\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "sample_submission_dataset = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "train.shape, test.shape, sample_submission_dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJiBZf9i50vU",
        "outputId": "3c743842-eb1f-4ab6-b720-01e849cf97a4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6079, 41), (476, 11), (476, 31))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data_point,\n",
        "dp = 1000\n",
        "train['question_title'][dp], train['question_body'][dp], train['answer'][dp]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVbd9YyL6pwH",
        "outputId": "45ca0cd5-8d3f-42c2-d411-daf323105161"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Using a Wiener Filter to Estimate a Transfer Function',\n",
              " 'As a follow-on to this question about estimating a transfer function of an unknown system using a Wiener filter, \\n\\n\\nHow would you put a minimum MSE criteria on how well the estimated filter weights matched the actual transfer function of the system? [Suppose you needed the MSE to be no more than -50dB]?\\nHow would you change his formulation if you wanted poles as well as zeroes (an IIR rather than an FIR filter)?\\n\\n',\n",
              " \"\\nThe desired MSE is application dependent, so there can be no general\\nrule. If the approximation doesn't satisfy your needs you can\\nincrease the filter length to obtain a better match.\\nThere is no straightforward way to change the FIR Wiener filter solution to an IIR solution because the IIR formulation results in a set of nonlinear equations which have no closed-form solution. The IIR solution might also be unstable, so FIR filters are a much more practical choice when computing a Wiener filter.\\n\\n\")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuando trabajamos con texto, generalmente realizamos una limpieza básica, como poner en minúsculas todas las palabras, eliminar tokens especiales (como '%', '$', '#', etc.), eliminar etiquetas HTML, etiquetas \\r, \\n (enter) con espacio y eliminar todos los caracteres especiales."
      ],
      "metadata": {
        "id": "XG5L6ihq72LL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words.remove('no'); stop_words.remove('not'); stop_words.remove('nor')\n",
        "\n",
        "def stopwrd_removal(sent):\n",
        "  lst = []\n",
        "  for wrd in sent.split():\n",
        "    if wrd not in stop_words:\n",
        "      lst.append(wrd)\n",
        "  return \" \".join(lst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uj8Zu3ldOpVp",
        "outputId": "cd8a371f-0539-4995-f045-8e7bd4444429"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preprocessor(column, remove_stopwords = False, remove_specialchar = False):\n",
        "  \"\"\"pass any column with Text in it from df_train | Note: returns nothing makes inplace changes in df_train\"\"\"\n",
        "\n",
        "  # 1. remove html tags, html urls, replace html comparison operators\n",
        "  train[column] = [re.sub('<.*?>', ' ', i) for i in train[column].values]\n",
        "  train[column] = train[column].str.replace('&lt;', '<')\\\n",
        "                                          .str.replace('&gt;', '>')\\\n",
        "                                          .str.replace('&le;', '<=' )\\\n",
        "                                          .str.replace('&ge;', '>=')\n",
        "\n",
        "  # 2. remove latex i,e., if there is any formulas or latex we have to remove it\n",
        "  train[column] = [re.sub('\\$.*?\\$', ' ', i) for i in train[column].values]\n",
        "\n",
        "  # 3. all lowercase\n",
        "  train[column] = train[column].str.lower()\n",
        "\n",
        "  # 4. decontractions\n",
        "  train[column] = train[column].str.replace(\"won't\", \"will not\").str.replace(\"can\\'t\", \"can not\").str.replace(\"n\\'t\", \" not\").str.replace(\"\\'re\", \" are\").str.\\\n",
        "                                                replace(\"\\'s\", \" is\").str.replace(\"\\'d\", \" would\").str.replace(\"\\'ll\", \" will\").str.\\\n",
        "                                                replace(\"\\'t\", \" not\").str.replace(\"\\'ve\", \" have\").str.replace(\"\\'m\", \" am\")\n",
        "\n",
        "  # 5. removing non-english or hebrew characters\n",
        "  train[column] = [i.encode(\"ascii\", \"ignore\").decode() for i in train[column].values]\n",
        "\n",
        "  # 6. remove all special-characters other than alpha-numericals\n",
        "  if remove_specialchar == True:\n",
        "    train[column] = [re.sub('[^A-Za-z0-9]+', ' ', i) for i in train[column].values]\n",
        "\n",
        "  # 7. separating special chars from alphanumerics\n",
        "  all_sc = [re.findall('[^ A-Za-z0-9]', i) for i in train[column].values]\n",
        "  special_char = np.unique([j for i in all_sc for j in i])\n",
        "  replace_char = [' '+i+' ' for i in special_char]\n",
        "  for i,j in zip(special_char, replace_char):\n",
        "    train[column] = train[column].str.replace(i, j)\n",
        "\n",
        "  # 8. Stop_word removal\n",
        "  if remove_stopwords == True:\n",
        "    train[column] = [stopwrd_removal(i) for i in train[column].values]\n",
        "\n",
        "  # 9. remove all white-space i.e., \\n, \\t, and extra_spaces\n",
        "  train[column] = train[column].str.replace(\"\\n\", \" \").str.replace(\"\\t\", \" \").str.rstrip()\n",
        "  train[column] = [re.sub('  +', ' ', i) for i in train[column].values]\n"
      ],
      "metadata": {
        "id": "-fcRrIOiOxTJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['clean_title'] = train['question_title']\n",
        "train['clean_body'] = train['question_body']\n",
        "train['clean_answer'] = train['answer']\n",
        "text_preprocessor('clean_title',  remove_stopwords = False, remove_specialchar = False)\n",
        "text_preprocessor('clean_body',  remove_stopwords = False, remove_specialchar = False)\n",
        "text_preprocessor('clean_answer',  remove_stopwords = False, remove_specialchar = False)"
      ],
      "metadata": {
        "id": "gt79r3ihPazb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = train['question_title'].values\n",
        "print('TITLE : ', text[0:5], '\\n')\n",
        "\n",
        "text = train['clean_title'].values\n",
        "print('CLEAN_TITLE : ',text[0:5], '\\n')\n",
        "\n",
        "text = train['question_body'].values\n",
        "print('BODY : ', text[0:5], '\\n')\n",
        "\n",
        "text = train['clean_body'].values\n",
        "print('CLEAN_BODY : ',text[0:5], '\\n')\n",
        "\n",
        "text = train['answer'].values\n",
        "print('ANSWER : ', text[0:5], '\\n')\n",
        "\n",
        "text = train['clean_answer'].values\n",
        "print('CLEAN_ANSWER : ', text[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mouhU-3EQNqZ",
        "outputId": "68a978d3-a0a1-460d-a3e3-de2781813676"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TITLE :  ['What am I losing when using extension tubes instead of a macro lens?'\n",
            " 'What is the distinction between a city and a sprawl/metroplex... between downtown and a commercial district?'\n",
            " 'Maximum protusion length for through-hole component pins'\n",
            " 'Can an affidavit be used in Beit Din?'\n",
            " 'How do you make a binary image in Photoshop?'] \n",
            "\n",
            "CLEAN_TITLE :  ['what am i losing when using extension tubes instead of a macro lens ?'\n",
            " 'what is the distinction between a city and a sprawl / metroplex . . . between downtown and a commercial district ?'\n",
            " 'maximum protusion length for through - hole component pins'\n",
            " 'can an affidavit be used in beit din ?'\n",
            " 'how do you make a binary image in photoshop ?'] \n",
            "\n",
            "BODY :  ['After playing around with macro photography on-the-cheap (read: reversed lens, rev. lens mounted on a straight lens, passive extension tubes), I would like to get further with this. The problems with the techniques I used is that focus is manual and aperture control is problematic at best. This limited my setup to still subjects (read: dead insects) Now, as spring is approaching, I want to be able to shoot live insects. I believe that for this, autofocus and settable aperture will be of great help.\\n\\nSo, one obvious but expensive option is a macro lens (say, EF 100mm Macro) However, I am not really interested in yet another prime lens. An alternative is the electrical extension tubes.\\n\\nExcept for maximum focusing distance, what am I losing when using tubes (coupled with a fine lens, say EF70-200/2.8) instead of a macro lens?\\n'\n",
            " 'I am trying to understand what kinds of places the spam values on p 231 refer to in the 5th Edition main book for Shadowrun.\\n\\nPer p 15, a sprawl is a plex, a plex is a \"metropolitan complex, short for metroplex\". Per Google a metroplex is \" a very large metropolitan area, especially one that is an aggregation of two or more cities\".  A city downtown and sprawl downtown would tend to have similar densities, but for some reason the sprawl (which includes suburbs?) has a higher spam zone noise rating (p 231).  Similarly, I\\'d think of a downtown as being more dense and noisy (e.g. Office buildings and street vendors) than a commercial district, e.g. an outdoor mall.  The noise ratings make me think that I am thinking about this incorrectly. What is a better way of thinking of them?\\n'\n",
            " 'I\\'m working on a PCB that has through-hole components on both sides of the board. The \"top\" side of the board is mounted flush to a Delrin plastic block (the only top-side component is a gas sensor that is fed air samples through hose fittings in the plastic block).\\n\\nThe flush mounting means that I have to add grooves to the plastic block to accommodate the soldered pins of the bottom-side components. Assuming a standard 0.062\" thickness FR4 board, how deep do I need to make the grooves in the plastic block? The only thing I could find is this NASA workmanship standard that states 0.5mm to 2.29mm, but I\\'m not sure if that will always hold true.\\n'\n",
            " \"An affidavit, from what i understand, is basically a signed document given by a witness to be used as evidence in a trial, without the witness themselves needing to take a stand.\\n\\nCan an affidavit be used in Beit Din? Or must witnesses take the stand in person for their testimony to count?\\n\\n(In case i'm misunderstanding what exactly an affidavit is, simply treat it as a signed document by a witness with their testimony.)\\n\"\n",
            " \"I am trying to make a binary image. I want more than just the look of the image to be black/white, but I want the actual file to be a binary file. Every pixel should be either black, or white. \\n\\nI don't just want a monochrome image. I can't have varying shades of gray, every pixel needs to be black or white.\\n\\nIs this possible? I looked under Image > Mode but nothing there seems to indiciate a binary style image.\\n\"] \n",
            "\n",
            "CLEAN_BODY :  ['after playing around with macro photography on - the - cheap ( read : reversed lens , rev . lens mounted on a straight lens , passive extension tubes ) , i would like to get further with this . the problems with the techniques i used is that focus is manual and aperture control is problematic at best . this limited my setup to still subjects ( read : dead insects ) now , as spring is approaching , i want to be able to shoot live insects . i believe that for this , autofocus and settable aperture will be of great help . so , one obvious but expensive option is a macro lens ( say , ef 100mm macro ) however , i am not really interested in yet another prime lens . an alternative is the electrical extension tubes . except for maximum focusing distance , what am i losing when using tubes ( coupled with a fine lens , say ef70 - 200 / 2 . 8 ) instead of a macro lens ?'\n",
            " 'i am trying to understand what kinds of places the spam values on p 231 refer to in the 5th edition main book for shadowrun . per p 15 , a sprawl is a plex , a plex is a \" metropolitan complex , short for metroplex \" . per google a metroplex is \" a very large metropolitan area , especially one that is an aggregation of two or more cities \" . a city downtown and sprawl downtown would tend to have similar densities , but for some reason the sprawl ( which includes suburbs ? ) has a higher spam zone noise rating ( p 231 ) . similarly , i would think of a downtown as being more dense and noisy ( e . g . office buildings and street vendors ) than a commercial district , e . g . an outdoor mall . the noise ratings make me think that i am thinking about this incorrectly . what is a better way of thinking of them ?'\n",
            " 'i am working on a pcb that has through - hole components on both sides of the board . the \" top \" side of the board is mounted flush to a delrin plastic block ( the only top - side component is a gas sensor that is fed air samples through hose fittings in the plastic block ) . the flush mounting means that i have to add grooves to the plastic block to accommodate the soldered pins of the bottom - side components . assuming a standard 0 . 062 \" thickness fr4 board , how deep do i need to make the grooves in the plastic block ? the only thing i could find is this nasa workmanship standard that states 0 . 5mm to 2 . 29mm , but i am not sure if that will always hold true .'\n",
            " 'an affidavit , from what i understand , is basically a signed document given by a witness to be used as evidence in a trial , without the witness themselves needing to take a stand . can an affidavit be used in beit din ? or must witnesses take the stand in person for their testimony to count ? ( in case i am misunderstanding what exactly an affidavit is , simply treat it as a signed document by a witness with their testimony . )'\n",
            " 'i am trying to make a binary image . i want more than just the look of the image to be black / white , but i want the actual file to be a binary file . every pixel should be either black , or white . i do not just want a monochrome image . i can not have varying shades of gray , every pixel needs to be black or white . is this possible ? i looked under image > mode but nothing there seems to indiciate a binary style image .'] \n",
            "\n",
            "ANSWER :  [\"I just got extension tubes, so here's the skinny.\\n\\n\\n  ...what am I losing when using tubes...?\\n\\n\\nA very considerable amount of light!  Increasing that distance from the end of the lens to the sensor can cut your light several stops.  Combined with the fact that you'll usually shoot stopped down - expect to need to increase your ISO considerably.\\n\\nThe fact the macro's are usually considered very very sharp, although I believe that 70-200mm 2.8 is supposed to be quite sharp.\\n\\nThe ultra low distortion typical of many macros.\\n\\nI wouldn't worry too much about the bokeh since the DOF will still be quite limited.\\n\\nCoupled on my 50mm, a full 60mm'ish extension tube results in a DOF of about a couple inches in front of the lens.  On my 70-300, its probably around 2-3 feet in front of the lens to about a foot in front of the lens.\\n\"\n",
            " \"It might be helpful to look into the definition of spam zone:\\n\\n(p.216) spam zone: An area flooded with invasive and/or viral AR advertising, causing noise.\\n\\nBecause a metroplex has so many marketing targets, it seems a safe assumption that marketers would drown the plex with spam. Spam from the less dense areas would bleed into the urban cores. A smaller city with less urban/suburban territory surrounding it ostensibly wouldn't have as much spam.\\n\"\n",
            " 'Do you even need grooves?  We make several products using through-hole components that are intended to mount using VHB double-sided foam tape.  The boards are 0.062\" thick double-sided with PTH and we use a table-top vertical belt sander to bring the component leads almost flush with the solder mask.  In other words, the solder mask isn\\'t touched by the sand paper but the leads are all sanded flat and sitting just proud of the solder mask.\\n\\nThis works well for small boards.\\n\\nFor what it\\'s worth, there are commercial machines available that use a rotary saw blade to do the same thing.  The board is held horizontal in a mounting / clamping system on the base and the saw motor is vertical on a sliding X-Y mechanism.  The saw blade simply cuts all of the leads almost flush with the board surface.  \\n\\nThis system is suited for boards of all sizes but especially for those boards larger than can be handled easily to be sanded with the belt sander.\\n\\nAlso note that these techniques are suitable only for PC boards with plated-through holes.  \\n'\n",
            " 'Sending an \"affidavit\" it is a dispute between Rashi and Rabbeinu Tam.\\n\\nDevarim 19:15:\\n\\n\\n  לא יקום עד אחד באיש לכל עון ולכל חטאת בכל חטא אשר יחטא על פי שני עדים או על פי שלשה עדים יקום דבר\\n\\n\\nRashi:\\n\\n\\n  ולא שיכתבו עדותם באגרת וישלחו לבית דין\\n  \\n  And not that they write their testimony in a letter and send it to Beis Din\\n\\n\\nTosefos Bava Basra 40a (continued from 39b):\\n\\n\\n  ועוד אומר ר\"י ששמע מן ר\"ת שנוהגים לשלח העדים עדותם באיגרת לב\"ד וחשיב עדות והא דדרשינן בספרי. מפיהם ולא מפי כתבם לא אתא אלא למעוטי דוקא אלם שאינו בר הגדה אבל ראוי להגדה אין הגדה מעכבת בו \\n  \\n  R\"i said that he heard from Rabbeinu Tam that the custom is to send testimony by a letter and it is considered [valid] testimony.  And that which it expounds in the Sifre \"From their mouths and not from their writing\" is only coming to exclude a mute who is not able to speak, but someone who is able to speak does not need to speak.\\n\\n\\nRambam concludes it is not allowed, but in monetary law the Chachomim enacted that it would be accepted in order to not prohibit the ability of people to secure loans (Hilchos Edus 3:4)\\n\\n\\n  דין תורה שאין מקבלין עדות, לא בדיני ממונות ולא בדיני נפשות, אלא מפי העדים:  שנאמר \"על פי שניים עדים\" (דברים יז,ו)--מפיהם, ולא מכתב ידן.  אבל מדברי סופרים שחותכין דיני ממונות בעדות שבשטר, אף על פי שאין העדים קיימין, כדי שלא תנעול דלת בפני לווין.\\n\\n'\n",
            " 'Check out Image Trace in Adobe Illustrator. \\n\\nI like using python and PIL, however.\\n\\nfrom PIL import Image\\nimage_file = Image.open(\"myimage.bmp\") \\nimage_file = image_file.convert(\\'1\\') # convert\\nimage_file.save(\\'result.bmp\\')\\n\\n'] \n",
            "\n",
            "CLEAN_ANSWER :  [\"i just got extension tubes , so here is the skinny . . . . what am i losing when using tubes . . . ? a very considerable amount of light ! increasing that distance from the end of the lens to the sensor can cut your light several stops . combined with the fact that you will usually shoot stopped down - expect to need to increase your iso considerably . the fact the macro is are usually considered very very sharp , although i believe that 70 - 200mm 2 . 8 is supposed to be quite sharp . the ultra low distortion typical of many macros . i would not worry too much about the bokeh since the dof will still be quite limited . coupled on my 50mm , a full 60mm ' ish extension tube results in a dof of about a couple inches in front of the lens . on my 70 - 300 , its probably around 2 - 3 feet in front of the lens to about a foot in front of the lens .\"\n",
            " 'it might be helpful to look into the definition of spam zone : ( p . 216 ) spam zone : an area flooded with invasive and / or viral ar advertising , causing noise . because a metroplex has so many marketing targets , it seems a safe assumption that marketers would drown the plex with spam . spam from the less dense areas would bleed into the urban cores . a smaller city with less urban / suburban territory surrounding it ostensibly would not have as much spam .'\n",
            " 'do you even need grooves ? we make several products using through - hole components that are intended to mount using vhb double - sided foam tape . the boards are 0 . 062 \" thick double - sided with pth and we use a table - top vertical belt sander to bring the component leads almost flush with the solder mask . in other words , the solder mask is not touched by the sand paper but the leads are all sanded flat and sitting just proud of the solder mask . this works well for small boards . for what it is worth , there are commercial machines available that use a rotary saw blade to do the same thing . the board is held horizontal in a mounting / clamping system on the base and the saw motor is vertical on a sliding x - y mechanism . the saw blade simply cuts all of the leads almost flush with the board surface . this system is suited for boards of all sizes but especially for those boards larger than can be handled easily to be sanded with the belt sander . also note that these techniques are suitable only for pc boards with plated - through holes .'\n",
            " 'sending an \" affidavit \" it is a dispute between rashi and rabbeinu tam . devarim 19 : 15 : rashi : and not that they write their testimony in a letter and send it to beis din tosefos bava basra 40a ( continued from 39b ) : \" \" \" . r \" i said that he heard from rabbeinu tam that the custom is to send testimony by a letter and it is considered [ valid ] testimony . and that which it expounds in the sifre \" from their mouths and not from their writing \" is only coming to exclude a mute who is not able to speak , but someone who is able to speak does not need to speak . rambam concludes it is not allowed , but in monetary law the chachomim enacted that it would be accepted in order to not prohibit the ability of people to secure loans ( hilchos edus 3 : 4 ) , , : \" \" ( , ) - - , . , , .'\n",
            " 'check out image trace in adobe illustrator . i like using python and pil , however . from pil import image image _ file = image . open ( \" myimage . bmp \" ) image _ file = image _ file . convert ( \\' 1 \\' ) # convert image _ file . save ( aresult . bmp \\' )']\n"
          ]
        }
      ]
    }
  ]
}